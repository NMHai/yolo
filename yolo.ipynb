{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pbcquoc/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.contrib.slim as slim\n",
    "import tensorflow.contrib.slim.nets\n",
    "from tensorflow.contrib.slim.nets import vgg \n",
    "from sklearn.model_selection import train_test_split\n",
    "import json\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "cell_size = 7\n",
    "box_per_cell = 2\n",
    "img_size = 224\n",
    "classes = {'circle':0, 'triangle':1,  'rectangle':2}\n",
    "nclass = len(classes)\n",
    "\n",
    "box_scale = 5.0\n",
    "noobject_scale = 0.5\n",
    "batch_size = 128\n",
    "epochs = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load():\n",
    "    labels = json.load(open('../data/yolo/train/labels.json'))\n",
    "    N = len(labels)\n",
    "    X = np.zeros((N, img_size, img_size, 3), dtype='uint8')\n",
    "    y = np.zeros((N,cell_size, cell_size, 5+nclass))\n",
    "    for idx, label in enumerate(labels):\n",
    "        img = cv2.imread(\"../data/yolo/train/{}.png\".format(idx))\n",
    "        X[idx] = img/255.0\n",
    "        for box in label['boxes']:\n",
    "            x1, y1 = box['x1'], box['y1']\n",
    "            x2, y2 = box['x2'], box['y2']\n",
    "            cl = [0]*len(classes)\n",
    "            cl[classes[box['class']]] = 1\n",
    "            \n",
    "            x_center, y_center, w, h = (x1+x2)/2.0, (y1+y2)/2.0, x2-x1, y2-y1\n",
    "            x_idx, y_idx = int(x_center/img_size*cell_size), int(y_center/img_size*cell_size)\n",
    "            y[idx, y_idx, x_idx] = 1, x_center, y_center, w, h, *cl\n",
    "    \n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = load()\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=2018)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_iou(boxes1, boxes2, scope='iou'):\n",
    "    \"\"\"calculate ious\n",
    "    Args:\n",
    "      boxes1: 5-D tensor [BATCH_SIZE, CELL_SIZE, CELL_SIZE, BOXES_PER_CELL, 4]  ====> (x_center, y_center, w, h)\n",
    "      boxes2: 5-D tensor [BATCH_SIZE, CELL_SIZE, CELL_SIZE, BOXES_PER_CELL, 4] ===> (x_center, y_center, w, h)\n",
    "    Return:\n",
    "      iou: 4-D tensor [BATCH_SIZE, CELL_SIZE, CELL_SIZE, BOXES_PER_CELL]\n",
    "    \"\"\"\n",
    "    with tf.variable_scope(scope):\n",
    "        # transform (x_center, y_center, w, h) to (x1, y1, x2, y2)\n",
    "        boxes1_t = tf.stack([boxes1[..., 0] - boxes1[..., 2] / 2.0,\n",
    "                             boxes1[..., 1] - boxes1[..., 3] / 2.0,\n",
    "                             boxes1[..., 0] + boxes1[..., 2] / 2.0,\n",
    "                             boxes1[..., 1] + boxes1[..., 3] / 2.0],\n",
    "                            axis=-1)\n",
    "\n",
    "        boxes2_t = tf.stack([boxes2[..., 0] - boxes2[..., 2] / 2.0,\n",
    "                             boxes2[..., 1] - boxes2[..., 3] / 2.0,\n",
    "                             boxes2[..., 0] + boxes2[..., 2] / 2.0,\n",
    "                             boxes2[..., 1] + boxes2[..., 3] / 2.0],\n",
    "                            axis=-1)\n",
    "\n",
    "        # calculate the left up point & right down point\n",
    "        lu = tf.maximum(boxes1_t[..., :2], boxes2_t[..., :2])\n",
    "        rd = tf.minimum(boxes1_t[..., 2:], boxes2_t[..., 2:])\n",
    "\n",
    "        # intersection\n",
    "        intersection = tf.maximum(0.0, rd - lu)\n",
    "        inter_square = intersection[..., 0] * intersection[..., 1]\n",
    "\n",
    "        # calculate the boxs1 square and boxs2 square\n",
    "        square1 = boxes1[..., 2] * boxes1[..., 3]\n",
    "        square2 = boxes2[..., 2] * boxes2[..., 3]\n",
    "\n",
    "        union_square = tf.maximum(square1 + square2 - inter_square, 1e-10)\n",
    "\n",
    "    return tf.clip_by_value(inter_square / union_square, 0.0, 1.0)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vgg16(inputs, is_training):\n",
    "    with tf.variable_scope(\"vgg_16\"):\n",
    "        with slim.arg_scope(vgg.vgg_arg_scope()):\n",
    "            net = slim.repeat(inputs, 2, slim.conv2d, 16, [3, 3], scope='conv1')\n",
    "            net = slim.max_pool2d(net, [2, 2], scope='pool1')\n",
    "            net = slim.repeat(net, 2, slim.conv2d, 32, [3, 3], scope='conv2')\n",
    "            net = slim.max_pool2d(net, [2, 2], scope='pool2')\n",
    "            net = slim.repeat(net, 2, slim.conv2d, 64, [3, 3], scope='conv3')\n",
    "            net = slim.max_pool2d(net, [2, 2], scope='pool3')\n",
    "            net = slim.repeat(net, 2, slim.conv2d, 128, [3, 3], scope='conv4')\n",
    "            net = slim.max_pool2d(net, [2, 2], scope='pool4')\n",
    "            net = slim.repeat(net, 2, slim.conv2d, 256, [3, 3], scope='conv5')\n",
    "            net = slim.max_pool2d(net, [2, 2], scope='pool5')\n",
    "            net = slim.conv2d(net, 512, [1, 1], scope='fc6')\n",
    "\n",
    "            net = slim.conv2d(net, 13, [1, 1], activation_fn=None, scope='fc7')\n",
    "    return net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_layer(predicts, labels, scope='loss_layer'):\n",
    "    with tf.variable_scope(scope):\n",
    "        offset = np.transpose(np.reshape(np.array(\n",
    "            [np.arange(cell_size)] * cell_size * box_per_cell),\n",
    "            (box_per_cell, cell_size, cell_size)), (1, 2, 0))\n",
    "        offset = offset[None, :]\n",
    "        offset = tf.constant(offset, dtype=tf.float32)\n",
    "        offset_tran = tf.transpose(offset, (0, 2, 1, 3))\n",
    "        predict_object = predicts[..., :box_per_cell]\n",
    "        predict_box_offset = tf.reshape(predicts[...,box_per_cell:5*box_per_cell], (-1, cell_size, cell_size, box_per_cell, 4))\n",
    "        predict_class = predicts[...,5*box_per_cell:]\n",
    "        predict_normalized_box = tf.stack(\n",
    "                                    [(predict_box_offset[..., 0] + offset) / cell_size,\n",
    "                                     (predict_box_offset[..., 1] + offset_tran) / cell_size,\n",
    "                                     tf.square(predict_box_offset[..., 2]),\n",
    "                                    tf.square(predict_box_offset[..., 3])], axis=-1)\n",
    "        \n",
    "        true_object = labels[..., :1]\n",
    "        true_box = tf.reshape(labels[..., 1:5], (-1, cell_size, cell_size, 1, 4))\n",
    "        true_normalized_box = tf.tile(true_box, (1, 1, 1, box_per_cell, 1))/img_size\n",
    "        true_class = labels[..., 5:]\n",
    "        true_box_offset =  tf.stack(\n",
    "                                    [true_normalized_box[..., 0] * cell_size - offset,\n",
    "                                     true_normalized_box[..., 1] * cell_size - offset_tran,\n",
    "                                     tf.sqrt(true_normalized_box[..., 2]),\n",
    "                                     tf.sqrt(true_normalized_box[..., 3])], axis=-1)\n",
    "        \n",
    "        predict_iou = compute_iou(true_normalized_box, predict_normalized_box)\n",
    "        \n",
    "        object_mask = tf.reduce_max(predict_iou, 3, keepdims=True)  \n",
    "        \n",
    "        iou_metric = tf.reduce_mean(tf.reduce_sum(object_mask, axis=[1,2,3])/tf.reduce_sum(true_object, axis=[1,2,3]))\n",
    "        \n",
    "        object_mask = tf.cast((predict_iou>=object_mask), tf.float32)*true_object\n",
    "\n",
    "        noobject_mask = tf.ones_like(object_mask) - object_mask\n",
    "        \n",
    "        ## class loss\n",
    "        class_delta = true_object*(predict_class - true_class)\n",
    "        class_loss = tf.reduce_mean(tf.reduce_sum(tf.square(class_delta), axis=[1,2,3]), name='class_loss')\n",
    "        ## object loss\n",
    "        object_delta = object_mask*(predict_object - predict_iou)\n",
    "        object_loss = tf.reduce_mean(tf.reduce_sum(tf.square(object_delta), axis=[1,2,3]), name='object_loss')\n",
    "        ## noobject loss\n",
    "        noobject_delta = noobject_mask*predict_object\n",
    "        noobject_loss = tf.reduce_mean(tf.reduce_sum(tf.square(noobject_delta), axis=[1,2,3]), name='noobject_loss')\n",
    "        ## coord loss\n",
    "        box_mask = tf.expand_dims(object_mask, 4)\n",
    "        box_delta = box_mask*(predict_box_offset - true_box_offset)\n",
    "        box_loss = tf.reduce_mean(tf.reduce_sum(tf.square(box_delta), axis=[1,2,3]), name='box_loss')\n",
    "        \n",
    "        loss = 0.5*class_loss + object_loss + 0.1*noobject_loss + 10*box_loss\n",
    "        \n",
    "        return loss, iou_metric, predict_object, predict_class, predict_normalized_box"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = tf.Graph()\n",
    "with graph.as_default():    \n",
    "    images = tf.placeholder(\"float\", [None, img_size, img_size, 3], name=\"input\")\n",
    "    labels = tf.placeholder('float', [None, cell_size, cell_size, 8], name='label')\n",
    "    is_training = tf.placeholder(tf.bool)\n",
    "\n",
    "    logits = vgg16(images, is_training)\n",
    "    loss, iou_metric, predict_object, predict_class, predict_normalized_box = loss_layer(logits, labels)\n",
    "            \n",
    "    optimizer = tf.train.AdadeltaOptimizer(5e-3)\n",
    "    train_op = optimizer.minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0 - running_time: 103s - train_loss: 3.569 - train_iou: 0.227 - val_loss: 3.629 - val_iou: 0.230\n"
     ]
    }
   ],
   "source": [
    "with tf.Session(graph=graph) as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        start_time = time.time()\n",
    "        for batch in range(len(X_train)//batch_size):\n",
    "            X_batch = X_train[batch*batch_size:(batch+1)*batch_size]\n",
    "            y_batch = y_train[batch*batch_size:(batch+1)*batch_size]\n",
    "            train_total_loss, train_iou_m,_ = sess.run([loss, iou_metric, train_op], {images:X_batch, labels:y_batch, is_training:True})            \n",
    "        end_time = time.time()\n",
    "        \n",
    "        val_loss = []\n",
    "        val_iou_ms = []\n",
    "        for batch in range(len(X_test)//batch_size):\n",
    "            val_X_batch = X_test[batch*batch_size:(batch+1)*batch_size]\n",
    "            val_y_batch = y_test[batch*batch_size:(batch+1)*batch_size]\n",
    "            total_val_loss, val_iou_m, val_predict_object, val_predict_class, val_predict_normalized_box = sess.run([loss, iou_metric, predict_object, predict_class, predict_normalized_box], \n",
    "                                                 {images:val_X_batch, labels:val_y_batch, is_training:False})\n",
    "            val_loss.append(total_val_loss)\n",
    "            val_iou_ms.append(val_iou_m)\n",
    "            \n",
    "        saver = tf.train.Saver(max_to_keep=1)\n",
    "        saver.save(sess, './yolo', global_step=epoch)\n",
    "        print('epoch: {} - running_time: {:.0f}s - train_loss: {:.3f} - train_iou: {:.3f} - val_loss: {:.3f} - val_iou: {:.3f}'.format(epoch, end_time - start_time, train_total_loss, train_iou_m, np.mean(val_loss), np.mean(val_iou_ms)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def iou(box1, box2):\n",
    "        tb = min(box1[0] + 0.5 * box1[2], box2[0] + 0.5 * box2[2]) - \\\n",
    "            max(box1[0] - 0.5 * box1[2], box2[0] - 0.5 * box2[2])\n",
    "        lr = min(box1[1] + 0.5 * box1[3], box2[1] + 0.5 * box2[3]) - \\\n",
    "            max(box1[1] - 0.5 * box1[3], box2[1] - 0.5 * box2[3])\n",
    "        inter = 0 if tb < 0 or lr < 0 else tb * lr\n",
    "        return inter / (box1[2] * box1[3] + box2[2] * box2[3] - inter)\n",
    "    \n",
    "def interpret_output(predict_object, predict_class, predict_normalized_box):\n",
    "    predict_box= predict_normalized_box*img_size\n",
    "    predict_object = np.expand_dims(predict_object, axis=-1)\n",
    "    predict_class = np.expand_dims(predict_class, axis=-2)\n",
    "    class_probs = predict_object*predict_class\n",
    "    \n",
    "    filter_mat_probs = np.array(class_probs >= 0.2, dtype='bool')\n",
    "    filter_mat_boxes = np.nonzero(filter_mat_probs)\n",
    "    boxes_filtered = predict_box[filter_mat_boxes[0], filter_mat_boxes[1], filter_mat_boxes[2]]\n",
    "    class_probs_filtered = class_probs[filter_mat_probs]\n",
    "       \n",
    "    classes_num_filtered = np.argmax(\n",
    "        filter_mat_probs, axis=3)[\n",
    "        filter_mat_boxes[0], filter_mat_boxes[1], filter_mat_boxes[2]]\n",
    "\n",
    "    argsort = np.array(np.argsort(class_probs_filtered))[::-1]\n",
    "    boxes_filtered = boxes_filtered[argsort]\n",
    "    class_probs_filtered = class_probs_filtered[argsort]\n",
    "    classes_num_filtered = classes_num_filtered[argsort]\n",
    "\n",
    "    for i in range(len(boxes_filtered)):\n",
    "        if class_probs_filtered[i] == 0:\n",
    "            continue\n",
    "        for j in range(i + 1, len(boxes_filtered)):\n",
    "            if iou(boxes_filtered[i], boxes_filtered[j]) > 0.5:\n",
    "                class_probs_filtered[j] = 0.0\n",
    "\n",
    "    filter_iou = np.array(class_probs_filtered > 0.0, dtype='bool')\n",
    "    boxes_filtered = boxes_filtered[filter_iou]\n",
    "    class_probs_filtered = class_probs_filtered[filter_iou]\n",
    "    classes_num_filtered = classes_num_filtered[filter_iou]\n",
    "\n",
    "    result = []\n",
    "    for i in range(len(boxes_filtered)):\n",
    "        result.append(\n",
    "            [classes_num_filtered[i],\n",
    "             boxes_filtered[i][0],\n",
    "             boxes_filtered[i][1],\n",
    "             boxes_filtered[i][2],\n",
    "             boxes_filtered[i][3],\n",
    "             class_probs_filtered[i]])\n",
    "\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0, 165.83449, 146.73402, 62.04014, 71.64465, 0.8006753],\n",
       " [1, 204.18887, 186.22862, 24.67078, 10.804721, 0.41302252],\n",
       " [1, 131.35335, 83.20642, 10.004929, 6.932067, 0.370794],\n",
       " [0, 154.7407, 144.78307, 43.834877, 33.171436, 0.25739604],\n",
       " [1, 36.221573, 8.834793, 9.048484, 4.7781663, 0.22912426]]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_idx = 0\n",
    "result = interpret_output(val_predict_object[img_idx], val_predict_class[img_idx], val_predict_normalized_box[img_idx])\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def draw_result(img, result):\n",
    "        for i in range(len(result)):\n",
    "            x = int(result[i][1])\n",
    "            y = int(result[i][2])\n",
    "            w = int(result[i][3] / 2)\n",
    "            h = int(result[i][4] / 2)\n",
    "            cv2.rectangle(img, (x - w, y - h), (x + w, y + h), (0, 255, 0), 2)\n",
    "            cv2.rectangle(img, (x - w, y - h - 20),\n",
    "                          (x + w, y - h), (46, 204, 113,0.5), -1)\n",
    "            lineType = cv2.LINE_AA if cv2.__version__ > '3' else cv2.CV_AA\n",
    "            cv2.putText(\n",
    "                img, '{} : {:.2f}'.format(result[i][0] ,result[i][5]),\n",
    "                (x - w + 5, y - h - 7), cv2.FONT_HERSHEY_SIMPLEX, 0.3,\n",
    "                (0, 0, 0), 1, lineType)\n",
    "            plt.imshow(img)\n",
    "draw_result(val_X_batch[img_idx]*255, result)            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x = np.nonzero(val_y_batch[img_idx][:,:,0])\n",
    "# x_label =  np.concatenate([val_y_batch[img_idx][x[0], x[1]][:,:5],\n",
    "#         np.argmax(val_y_batch[img_idx][x[0], x[1]][:,5:], axis=1).reshape((5,1))],\n",
    "#                   axis=-1)\n",
    "# draw_result(val_X_batch[img_idx]*255, x_label)            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
