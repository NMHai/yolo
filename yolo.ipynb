{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pbcquoc/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.contrib.slim as slim\n",
    "import tensorflow.contrib.slim.nets\n",
    "from tensorflow.contrib.slim.nets import vgg \n",
    "from sklearn.model_selection import train_test_split\n",
    "import json\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "cell_size = 7\n",
    "box_per_cell = 2\n",
    "img_size = 224\n",
    "classes = {'circle':0, 'triangle':1,  'rectangle':2}\n",
    "nclass = len(classes)\n",
    "\n",
    "box_scale = 5.0\n",
    "noobject_scale = 0.5\n",
    "batch_size = 128\n",
    "epochs = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load():\n",
    "    labels = json.load(open('../data/yolo/train/labels.json'))\n",
    "    N = len(labels)\n",
    "    X = np.zeros((N, img_size, img_size, 3), dtype='uint8')\n",
    "    y = np.zeros((N,cell_size, cell_size, 5+nclass))\n",
    "    for idx, label in enumerate(labels):\n",
    "        img = cv2.imread(\"../data/yolo/train/{}.png\".format(idx))\n",
    "        X[idx] = img/255.0\n",
    "        for box in label['boxes']:\n",
    "            x1, y1 = box['x1'], box['y1']\n",
    "            x2, y2 = box['x2'], box['y2']\n",
    "            cl = [0]*len(classes)\n",
    "            cl[classes[box['class']]] = 1\n",
    "            \n",
    "            x_center, y_center, w, h = (x1+x2)/2.0, (y1+y2)/2.0, x2-x1, y2-y1\n",
    "            x_idx, y_idx = int(x_center/img_size*cell_size), int(y_center/img_size*cell_size)\n",
    "            y[idx, y_idx, x_idx] = 1, x_center, y_center, w, h, *cl\n",
    "    \n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = load()\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=2018)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_iou(boxes1, boxes2, scope='iou'):\n",
    "    \"\"\"calculate ious\n",
    "    Args:\n",
    "      boxes1: 5-D tensor [BATCH_SIZE, CELL_SIZE, CELL_SIZE, BOXES_PER_CELL, 4]  ====> (x_center, y_center, w, h)\n",
    "      boxes2: 5-D tensor [BATCH_SIZE, CELL_SIZE, CELL_SIZE, BOXES_PER_CELL, 4] ===> (x_center, y_center, w, h)\n",
    "    Return:\n",
    "      iou: 4-D tensor [BATCH_SIZE, CELL_SIZE, CELL_SIZE, BOXES_PER_CELL]\n",
    "    \"\"\"\n",
    "    with tf.variable_scope(scope):\n",
    "        # transform (x_center, y_center, w, h) to (x1, y1, x2, y2)\n",
    "        boxes1_t = tf.stack([boxes1[..., 0] - boxes1[..., 2] / 2.0,\n",
    "                             boxes1[..., 1] - boxes1[..., 3] / 2.0,\n",
    "                             boxes1[..., 0] + boxes1[..., 2] / 2.0,\n",
    "                             boxes1[..., 1] + boxes1[..., 3] / 2.0],\n",
    "                            axis=-1)\n",
    "\n",
    "        boxes2_t = tf.stack([boxes2[..., 0] - boxes2[..., 2] / 2.0,\n",
    "                             boxes2[..., 1] - boxes2[..., 3] / 2.0,\n",
    "                             boxes2[..., 0] + boxes2[..., 2] / 2.0,\n",
    "                             boxes2[..., 1] + boxes2[..., 3] / 2.0],\n",
    "                            axis=-1)\n",
    "\n",
    "        # calculate the left up point & right down point\n",
    "        lu = tf.maximum(boxes1_t[..., :2], boxes2_t[..., :2])\n",
    "        rd = tf.minimum(boxes1_t[..., 2:], boxes2_t[..., 2:])\n",
    "\n",
    "        # intersection\n",
    "        intersection = tf.maximum(0.0, rd - lu)\n",
    "        inter_square = intersection[..., 0] * intersection[..., 1]\n",
    "\n",
    "        # calculate the boxs1 square and boxs2 square\n",
    "        square1 = boxes1[..., 2] * boxes1[..., 3]\n",
    "        square2 = boxes2[..., 2] * boxes2[..., 3]\n",
    "\n",
    "        union_square = tf.maximum(square1 + square2 - inter_square, 1e-10)\n",
    "\n",
    "    return tf.clip_by_value(inter_square / union_square, 0.0, 1.0)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vgg16(inputs, is_training):\n",
    "    with tf.variable_scope(\"vgg_16\"):\n",
    "        with slim.arg_scope(vgg.vgg_arg_scope()):\n",
    "            net = slim.repeat(inputs, 2, slim.conv2d, 16, [3, 3], scope='conv1')\n",
    "            net = slim.max_pool2d(net, [2, 2], scope='pool1')\n",
    "            net = slim.repeat(net, 2, slim.conv2d, 32, [3, 3], scope='conv2')\n",
    "            net = slim.max_pool2d(net, [2, 2], scope='pool2')\n",
    "            net = slim.repeat(net, 2, slim.conv2d, 64, [3, 3], scope='conv3')\n",
    "            net = slim.max_pool2d(net, [2, 2], scope='pool3')\n",
    "            net = slim.repeat(net, 2, slim.conv2d, 128, [3, 3], scope='conv4')\n",
    "            net = slim.max_pool2d(net, [2, 2], scope='pool4')\n",
    "            net = slim.repeat(net, 2, slim.conv2d, 256, [3, 3], scope='conv5')\n",
    "            net = slim.max_pool2d(net, [2, 2], scope='pool5')\n",
    "            net = slim.conv2d(net, 512, [1, 1], scope='fc6')\n",
    "\n",
    "            net = slim.conv2d(net, 13, [1, 1], activation_fn=None, scope='fc7')\n",
    "    return net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_layer(predicts, labels, scope='loss_layer'):\n",
    "    with tf.variable_scope(scope):\n",
    "        offset = np.transpose(np.reshape(np.array(\n",
    "            [np.arange(cell_size)] * cell_size * box_per_cell),\n",
    "            (box_per_cell, cell_size, cell_size)), (1, 2, 0))\n",
    "        offset = offset[None, :]\n",
    "        offset = tf.constant(offset, dtype=tf.float32)\n",
    "        offset_tran = tf.transpose(offset, (0, 2, 1, 3))\n",
    "        predict_object = predicts[..., :box_per_cell]\n",
    "        predict_box_offset = tf.reshape(predicts[...,box_per_cell:5*box_per_cell], (-1, cell_size, cell_size, box_per_cell, 4))\n",
    "        predict_class = predicts[...,5*box_per_cell:]\n",
    "        predict_normalized_box = tf.stack(\n",
    "                                    [(predict_box_offset[..., 0] + offset) / cell_size,\n",
    "                                     (predict_box_offset[..., 1] + offset_tran) / cell_size,\n",
    "                                     tf.square(predict_box_offset[..., 2]),\n",
    "                                    tf.square(predict_box_offset[..., 3])], axis=-1)\n",
    "        \n",
    "        true_object = labels[..., :1]\n",
    "        true_box = tf.reshape(labels[..., 1:5], (-1, cell_size, cell_size, 1, 4))\n",
    "        true_normalized_box = tf.tile(true_box, (1, 1, 1, box_per_cell, 1))/img_size\n",
    "        true_class = labels[..., 5:]\n",
    "        true_box_offset =  tf.stack(\n",
    "                                    [true_normalized_box[..., 0] * cell_size - offset,\n",
    "                                     true_normalized_box[..., 1] * cell_size - offset_tran,\n",
    "                                     tf.sqrt(true_normalized_box[..., 2]),\n",
    "                                     tf.sqrt(true_normalized_box[..., 3])], axis=-1)\n",
    "        \n",
    "        predict_iou = compute_iou(true_normalized_box, predict_normalized_box)\n",
    "        \n",
    "        object_mask = tf.reduce_max(predict_iou, 3, keepdims=True)  \n",
    "        \n",
    "        iou_metric = tf.reduce_mean(tf.reduce_sum(object_mask, axis=[1,2,3])/tf.reduce_sum(true_object, axis=[1,2,3]))\n",
    "        \n",
    "        object_mask = tf.cast((predict_iou>=object_mask), tf.float32)*true_object\n",
    "\n",
    "        noobject_mask = tf.ones_like(object_mask) - object_mask\n",
    "        \n",
    "        ## class loss\n",
    "        class_delta = true_object*(predict_class - true_class)\n",
    "        class_loss = tf.reduce_mean(tf.reduce_sum(tf.square(class_delta), axis=[1,2,3]), name='class_loss')\n",
    "        ## object loss\n",
    "        object_delta = object_mask*(predict_object - predict_iou)\n",
    "        object_loss = tf.reduce_mean(tf.reduce_sum(tf.square(object_delta), axis=[1,2,3]), name='object_loss')\n",
    "        ## noobject loss\n",
    "        noobject_delta = noobject_mask*predict_object\n",
    "        noobject_loss = tf.reduce_mean(tf.reduce_sum(tf.square(noobject_delta), axis=[1,2,3]), name='noobject_loss')\n",
    "        ## coord loss\n",
    "        box_mask = tf.expand_dims(object_mask, 4)\n",
    "        box_delta = box_mask*(predict_box_offset - true_box_offset)\n",
    "        box_loss = tf.reduce_mean(tf.reduce_sum(tf.square(box_delta), axis=[1,2,3]), name='box_loss')\n",
    "        \n",
    "        loss = 0.5*class_loss + object_loss + 0.1*noobject_loss + 10*box_loss\n",
    "        \n",
    "        return loss, iou_metric, predict_object, predict_class, predict_normalized_box"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = tf.Graph()\n",
    "with graph.as_default():    \n",
    "    images = tf.placeholder(\"float\", [None, img_size, img_size, 3], name=\"input\")\n",
    "    labels = tf.placeholder('float', [None, cell_size, cell_size, 8], name='label')\n",
    "    is_training = tf.placeholder(tf.bool)\n",
    "\n",
    "    logits = vgg16(images, is_training)\n",
    "    loss, iou_metric, predict_object, predict_class, predict_normalized_box = loss_layer(logits, labels)\n",
    "            \n",
    "    optimizer = tf.train.AdadeltaOptimizer(5e-3)\n",
    "    train_op = optimizer.minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0 - running_time: 107s - train_loss: 3.538 - train_iou: 0.238 - val_loss: 3.590 - val_iou: 0.241\n",
      "epoch: 1 - running_time: 101s - train_loss: 3.150 - train_iou: 0.276 - val_loss: 3.214 - val_iou: 0.269\n",
      "epoch: 2 - running_time: 101s - train_loss: 2.808 - train_iou: 0.299 - val_loss: 2.854 - val_iou: 0.275\n",
      "epoch: 3 - running_time: 102s - train_loss: 2.566 - train_iou: 0.315 - val_loss: 2.612 - val_iou: 0.296\n",
      "epoch: 4 - running_time: 100s - train_loss: 2.393 - train_iou: 0.340 - val_loss: 2.434 - val_iou: 0.322\n",
      "epoch: 5 - running_time: 100s - train_loss: 2.268 - train_iou: 0.358 - val_loss: 2.302 - val_iou: 0.339\n",
      "epoch: 6 - running_time: 100s - train_loss: 2.168 - train_iou: 0.375 - val_loss: 2.201 - val_iou: 0.353\n",
      "epoch: 7 - running_time: 100s - train_loss: 2.097 - train_iou: 0.381 - val_loss: 2.116 - val_iou: 0.367\n",
      "epoch: 8 - running_time: 100s - train_loss: 2.035 - train_iou: 0.395 - val_loss: 2.040 - val_iou: 0.377\n",
      "epoch: 9 - running_time: 100s - train_loss: 1.986 - train_iou: 0.400 - val_loss: 1.977 - val_iou: 0.380\n",
      "epoch: 10 - running_time: 100s - train_loss: 1.938 - train_iou: 0.412 - val_loss: 1.913 - val_iou: 0.388\n",
      "epoch: 11 - running_time: 100s - train_loss: 1.883 - train_iou: 0.416 - val_loss: 1.860 - val_iou: 0.394\n",
      "epoch: 12 - running_time: 100s - train_loss: 1.831 - train_iou: 0.431 - val_loss: 1.803 - val_iou: 0.400\n",
      "epoch: 13 - running_time: 100s - train_loss: 1.781 - train_iou: 0.449 - val_loss: 1.751 - val_iou: 0.412\n",
      "epoch: 14 - running_time: 100s - train_loss: 1.733 - train_iou: 0.457 - val_loss: 1.704 - val_iou: 0.419\n",
      "epoch: 15 - running_time: 100s - train_loss: 1.700 - train_iou: 0.465 - val_loss: 1.660 - val_iou: 0.427\n",
      "epoch: 16 - running_time: 100s - train_loss: 1.653 - train_iou: 0.473 - val_loss: 1.621 - val_iou: 0.429\n",
      "epoch: 17 - running_time: 100s - train_loss: 1.616 - train_iou: 0.476 - val_loss: 1.583 - val_iou: 0.431\n",
      "epoch: 18 - running_time: 100s - train_loss: 1.579 - train_iou: 0.483 - val_loss: 1.546 - val_iou: 0.432\n",
      "epoch: 19 - running_time: 100s - train_loss: 1.538 - train_iou: 0.499 - val_loss: 1.514 - val_iou: 0.433\n",
      "epoch: 20 - running_time: 100s - train_loss: 1.507 - train_iou: 0.499 - val_loss: 1.479 - val_iou: 0.438\n",
      "epoch: 21 - running_time: 100s - train_loss: 1.481 - train_iou: 0.503 - val_loss: 1.453 - val_iou: 0.437\n",
      "epoch: 22 - running_time: 100s - train_loss: 1.452 - train_iou: 0.505 - val_loss: 1.425 - val_iou: 0.444\n",
      "epoch: 23 - running_time: 100s - train_loss: 1.426 - train_iou: 0.514 - val_loss: 1.400 - val_iou: 0.450\n",
      "epoch: 24 - running_time: 100s - train_loss: 1.409 - train_iou: 0.518 - val_loss: 1.378 - val_iou: 0.448\n",
      "epoch: 25 - running_time: 100s - train_loss: 1.398 - train_iou: 0.491 - val_loss: 1.348 - val_iou: 0.462\n",
      "epoch: 26 - running_time: 100s - train_loss: 1.386 - train_iou: 0.531 - val_loss: 1.336 - val_iou: 0.446\n",
      "epoch: 27 - running_time: 100s - train_loss: 1.363 - train_iou: 0.491 - val_loss: 1.301 - val_iou: 0.474\n",
      "epoch: 28 - running_time: 100s - train_loss: 1.350 - train_iou: 0.543 - val_loss: 1.286 - val_iou: 0.459\n",
      "epoch: 29 - running_time: 100s - train_loss: 1.334 - train_iou: 0.547 - val_loss: 1.265 - val_iou: 0.466\n",
      "epoch: 30 - running_time: 100s - train_loss: 1.304 - train_iou: 0.496 - val_loss: 1.240 - val_iou: 0.487\n",
      "epoch: 31 - running_time: 100s - train_loss: 1.285 - train_iou: 0.540 - val_loss: 1.235 - val_iou: 0.454\n",
      "epoch: 32 - running_time: 101s - train_loss: 1.277 - train_iou: 0.550 - val_loss: 1.214 - val_iou: 0.466\n",
      "epoch: 33 - running_time: 102s - train_loss: 1.252 - train_iou: 0.476 - val_loss: 1.189 - val_iou: 0.521\n",
      "epoch: 34 - running_time: 101s - train_loss: 1.233 - train_iou: 0.485 - val_loss: 1.171 - val_iou: 0.515\n",
      "epoch: 35 - running_time: 104s - train_loss: 1.219 - train_iou: 0.485 - val_loss: 1.156 - val_iou: 0.521\n",
      "epoch: 36 - running_time: 104s - train_loss: 1.204 - train_iou: 0.493 - val_loss: 1.140 - val_iou: 0.518\n",
      "epoch: 37 - running_time: 104s - train_loss: 1.201 - train_iou: 0.561 - val_loss: 1.138 - val_iou: 0.475\n",
      "epoch: 38 - running_time: 104s - train_loss: 1.168 - train_iou: 0.516 - val_loss: 1.115 - val_iou: 0.501\n",
      "epoch: 39 - running_time: 104s - train_loss: 1.170 - train_iou: 0.566 - val_loss: 1.109 - val_iou: 0.487\n",
      "epoch: 40 - running_time: 104s - train_loss: 1.142 - train_iou: 0.518 - val_loss: 1.091 - val_iou: 0.502\n",
      "epoch: 41 - running_time: 104s - train_loss: 1.141 - train_iou: 0.567 - val_loss: 1.083 - val_iou: 0.491\n",
      "epoch: 42 - running_time: 103s - train_loss: 1.128 - train_iou: 0.568 - val_loss: 1.069 - val_iou: 0.497\n",
      "epoch: 43 - running_time: 100s - train_loss: 1.115 - train_iou: 0.569 - val_loss: 1.061 - val_iou: 0.492\n",
      "epoch: 44 - running_time: 102s - train_loss: 1.087 - train_iou: 0.515 - val_loss: 1.041 - val_iou: 0.529\n",
      "epoch: 45 - running_time: 101s - train_loss: 1.076 - train_iou: 0.539 - val_loss: 1.037 - val_iou: 0.500\n",
      "epoch: 46 - running_time: 102s - train_loss: 1.077 - train_iou: 0.497 - val_loss: 1.027 - val_iou: 0.552\n",
      "epoch: 47 - running_time: 100s - train_loss: 1.060 - train_iou: 0.526 - val_loss: 1.010 - val_iou: 0.523\n",
      "epoch: 48 - running_time: 100s - train_loss: 1.051 - train_iou: 0.539 - val_loss: 1.001 - val_iou: 0.514\n",
      "epoch: 49 - running_time: 100s - train_loss: 1.041 - train_iou: 0.523 - val_loss: 0.990 - val_iou: 0.539\n"
     ]
    }
   ],
   "source": [
    "with tf.Session(graph=graph) as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        start_time = time.time()\n",
    "        for batch in range(len(X_train)//batch_size):\n",
    "            X_batch = X_train[batch*batch_size:(batch+1)*batch_size]\n",
    "            y_batch = y_train[batch*batch_size:(batch+1)*batch_size]\n",
    "            train_total_loss, train_iou_m,_ = sess.run([loss, iou_metric, train_op], {images:X_batch, labels:y_batch, is_training:True})            \n",
    "        end_time = time.time()\n",
    "        \n",
    "        val_loss = []\n",
    "        val_iou_ms = []\n",
    "        for batch in range(len(X_test)//batch_size):\n",
    "            val_X_batch = X_test[batch*batch_size:(batch+1)*batch_size]\n",
    "            val_y_batch = y_test[batch*batch_size:(batch+1)*batch_size]\n",
    "            total_val_loss, val_iou_m, val_predict_object, val_predict_class, val_predict_normalized_box = sess.run([loss, iou_metric, predict_object, predict_class, predict_normalized_box], \n",
    "                                                 {images:val_X_batch, labels:val_y_batch, is_training:False})\n",
    "            val_loss.append(total_val_loss)\n",
    "            val_iou_ms.append(val_iou_m)\n",
    "            \n",
    "        print('epoch: {} - running_time: {:.0f}s - train_loss: {:.3f} - train_iou: {:.3f} - val_loss: {:.3f} - val_iou: {:.3f}'.format(epoch, end_time - start_time, train_total_loss, train_iou_m, np.mean(val_loss), np.mean(val_iou_ms)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def interpret_output(predict_object, predict_class, predict_normalized_box):\n",
    "    predict_box= predict_normalized_box*img_size\n",
    "    predict_object = np.expand_dims(predict_object, axis=-1)\n",
    "    predict_class = np.expand_dims(predict_class, axis=-2)\n",
    "    class_probs = predict_object*predict_class\n",
    "    \n",
    "    filter_mat_probs = np.array(class_probs >= 0.2, dtype='bool')\n",
    "    filter_mat_boxes = np.nonzero(filter_mat_probs)\n",
    "    boxes_filtered = predict_box[filter_mat_boxes[0], filter_mat_boxes[1], filter_mat_boxes[2]]\n",
    "    class_probs_filtered = class_probs[filter_mat_probs]\n",
    "    print(class_probs.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7086825\n"
     ]
    }
   ],
   "source": [
    "interpret_output(val_predict_object[0], val_predict_class[0], val_predict_normalized_box[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
