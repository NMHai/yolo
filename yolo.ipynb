{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/ducnt4/opt/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.contrib.slim as slim\n",
    "import tensorflow.contrib.slim.nets\n",
    "from tensorflow.contrib.slim.nets import vgg \n",
    "from sklearn.model_selection import train_test_split\n",
    "import json\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "cell_size = 7\n",
    "box_per_cell = 2\n",
    "img_size = 224\n",
    "classes = {'circle':0, 'triangle':1,  'rectangle':2}\n",
    "nclass = len(classes)\n",
    "\n",
    "box_scale = 5.0\n",
    "noobject_scale = 0.5\n",
    "batch_size = 128\n",
    "epochs = 100\n",
    "lr = 1e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load():\n",
    "    labels = json.load(open('../data/yolo/train/labels.json'))\n",
    "    N = len(labels)\n",
    "    X = np.zeros((N, img_size, img_size, 3), dtype='uint8')\n",
    "    y = np.zeros((N,cell_size, cell_size, 5+nclass))\n",
    "    for idx, label in enumerate(labels):\n",
    "        img = cv2.imread(\"../data/yolo/train/{}.png\".format(idx))\n",
    "        X[idx] = img/255.0\n",
    "        for box in label['boxes']:\n",
    "            x1, y1 = box['x1'], box['y1']\n",
    "            x2, y2 = box['x2'], box['y2']\n",
    "            cl = [0]*len(classes)\n",
    "            cl[classes[box['class']]] = 1\n",
    "            \n",
    "            x_center, y_center, w, h = (x1+x2)/2.0, (y1+y2)/2.0, x2-x1, y2-y1\n",
    "            x_idx, y_idx = int(x_center/img_size*cell_size), int(y_center/img_size*cell_size)\n",
    "            y[idx, y_idx, x_idx] = 1, x_center, y_center, w, h, *cl\n",
    "    \n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = load()\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=2018)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_iou(boxes1, boxes2, scope='iou'):\n",
    "    \"\"\"calculate ious\n",
    "    Args:\n",
    "      boxes1: 5-D tensor [BATCH_SIZE, CELL_SIZE, CELL_SIZE, BOXES_PER_CELL, 4]  ====> (x_center, y_center, w, h)\n",
    "      boxes2: 5-D tensor [BATCH_SIZE, CELL_SIZE, CELL_SIZE, BOXES_PER_CELL, 4] ===> (x_center, y_center, w, h)\n",
    "    Return:\n",
    "      iou: 4-D tensor [BATCH_SIZE, CELL_SIZE, CELL_SIZE, BOXES_PER_CELL]\n",
    "    \"\"\"\n",
    "    with tf.variable_scope(scope):\n",
    "        # transform (x_center, y_center, w, h) to (x1, y1, x2, y2)\n",
    "        boxes1_t = tf.stack([boxes1[..., 0] - boxes1[..., 2] / 2.0,\n",
    "                             boxes1[..., 1] - boxes1[..., 3] / 2.0,\n",
    "                             boxes1[..., 0] + boxes1[..., 2] / 2.0,\n",
    "                             boxes1[..., 1] + boxes1[..., 3] / 2.0],\n",
    "                            axis=-1)\n",
    "\n",
    "        boxes2_t = tf.stack([boxes2[..., 0] - boxes2[..., 2] / 2.0,\n",
    "                             boxes2[..., 1] - boxes2[..., 3] / 2.0,\n",
    "                             boxes2[..., 0] + boxes2[..., 2] / 2.0,\n",
    "                             boxes2[..., 1] + boxes2[..., 3] / 2.0],\n",
    "                            axis=-1)\n",
    "\n",
    "        # calculate the left up point & right down point\n",
    "        lu = tf.maximum(boxes1_t[..., :2], boxes2_t[..., :2])\n",
    "        rd = tf.minimum(boxes1_t[..., 2:], boxes2_t[..., 2:])\n",
    "\n",
    "        # intersection\n",
    "        intersection = tf.maximum(0.0, rd - lu)\n",
    "        inter_square = intersection[..., 0] * intersection[..., 1]\n",
    "\n",
    "        # calculate the boxs1 square and boxs2 square\n",
    "        square1 = boxes1[..., 2] * boxes1[..., 3]\n",
    "        square2 = boxes2[..., 2] * boxes2[..., 3]\n",
    "\n",
    "        union_square = tf.maximum(square1 + square2 - inter_square, 1e-10)\n",
    "\n",
    "    return tf.clip_by_value(inter_square / union_square, 0.0, 1.0)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vgg16(inputs, is_training):\n",
    "    with tf.variable_scope(\"vgg_16\"):\n",
    "        with slim.arg_scope(vgg.vgg_arg_scope()):\n",
    "            net = slim.repeat(inputs, 2, slim.conv2d, 16, [3, 3], scope='conv1')\n",
    "            net = slim.max_pool2d(net, [2, 2], scope='pool1')\n",
    "            net = slim.repeat(net, 2, slim.conv2d, 32, [3, 3], scope='conv2')\n",
    "            net = slim.max_pool2d(net, [2, 2], scope='pool2')\n",
    "            net = slim.repeat(net, 2, slim.conv2d, 64, [3, 3], scope='conv3')\n",
    "            net = slim.max_pool2d(net, [2, 2], scope='pool3')\n",
    "            net = slim.repeat(net, 2, slim.conv2d, 128, [3, 3], scope='conv4')\n",
    "            net = slim.max_pool2d(net, [2, 2], scope='pool4')\n",
    "            net = slim.repeat(net, 2, slim.conv2d, 256, [3, 3], scope='conv5')\n",
    "            net = slim.max_pool2d(net, [2, 2], scope='pool5')\n",
    "\n",
    "            net = slim.conv2d(net, 512, [1, 1], scope='fc6')   \n",
    "\n",
    "            net = slim.conv2d(net, 13, [1, 1], activation_fn=None, scope='fc7')\n",
    "    return net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_layer(predicts, labels, scope='loss_layer'):\n",
    "    with tf.variable_scope(scope):\n",
    "        offset = np.transpose(np.reshape(np.array(\n",
    "            [np.arange(cell_size)] * cell_size * box_per_cell),\n",
    "            (box_per_cell, cell_size, cell_size)), (1, 2, 0))\n",
    "        offset = offset[None, :]\n",
    "        offset = tf.constant(offset, dtype=tf.float32)\n",
    "        offset_tran = tf.transpose(offset, (0, 2, 1, 3))\n",
    "        predict_object = predicts[..., :box_per_cell]\n",
    "        predict_box_offset = tf.reshape(predicts[...,box_per_cell:5*box_per_cell], (-1, cell_size, cell_size, box_per_cell, 4))\n",
    "        predict_class = predicts[...,5*box_per_cell:]\n",
    "        predict_normalized_box = tf.stack(\n",
    "                                    [(predict_box_offset[..., 0] + offset) / cell_size,\n",
    "                                     (predict_box_offset[..., 1] + offset_tran) / cell_size,\n",
    "                                     tf.square(predict_box_offset[..., 2]),\n",
    "                                    tf.square(predict_box_offset[..., 3])], axis=-1)\n",
    "        \n",
    "        true_object = labels[..., :1]\n",
    "        true_box = tf.reshape(labels[..., 1:5], (-1, cell_size, cell_size, 1, 4))\n",
    "        true_normalized_box = tf.tile(true_box, (1, 1, 1, box_per_cell, 1))/img_size\n",
    "        true_class = labels[..., 5:]\n",
    "        true_box_offset =  tf.stack(\n",
    "                                    [true_normalized_box[..., 0] * cell_size - offset,\n",
    "                                     true_normalized_box[..., 1] * cell_size - offset_tran,\n",
    "                                     tf.sqrt(true_normalized_box[..., 2]),\n",
    "                                     tf.sqrt(true_normalized_box[..., 3])], axis=-1)\n",
    "        \n",
    "        predict_iou = compute_iou(true_normalized_box, predict_normalized_box)\n",
    "        \n",
    "        object_mask = tf.reduce_max(predict_iou, 3, keepdims=True)  \n",
    "        \n",
    "        iou_metric = tf.reduce_mean(tf.reduce_sum(object_mask, axis=[1,2,3])/tf.reduce_sum(true_object, axis=[1,2,3]))\n",
    "        \n",
    "        object_mask = tf.cast((predict_iou>=object_mask), tf.float32)*true_object\n",
    "\n",
    "        noobject_mask = tf.ones_like(object_mask) - object_mask\n",
    "        \n",
    "        ## class loss\n",
    "        class_delta = true_object*(predict_class - true_class)\n",
    "        class_loss = tf.reduce_mean(tf.reduce_sum(tf.square(class_delta), axis=[1,2,3]), name='class_loss')\n",
    "        ## object loss\n",
    "        object_delta = object_mask*(predict_object - predict_iou)\n",
    "        object_loss = tf.reduce_mean(tf.reduce_sum(tf.square(object_delta), axis=[1,2,3]), name='object_loss')\n",
    "        ## noobject loss\n",
    "        noobject_delta = noobject_mask*predict_object\n",
    "        noobject_loss = tf.reduce_mean(tf.reduce_sum(tf.square(noobject_delta), axis=[1,2,3]), name='noobject_loss')\n",
    "        ## coord loss\n",
    "        box_mask = tf.expand_dims(object_mask, 4)\n",
    "        box_delta = box_mask*(predict_box_offset - true_box_offset)\n",
    "        box_loss = tf.reduce_mean(tf.reduce_sum(tf.square(box_delta), axis=[1,2,3]), name='box_loss')\n",
    "        \n",
    "        loss = 0.5*class_loss + object_loss + 0.1*noobject_loss + 10*box_loss\n",
    "        \n",
    "        return loss, iou_metric, predict_object, predict_class, predict_normalized_box"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = tf.Graph()\n",
    "with graph.as_default():    \n",
    "    images = tf.placeholder(\"float\", [None, img_size, img_size, 3], name=\"input\")\n",
    "    labels = tf.placeholder('float', [None, cell_size, cell_size, 8], name='label')\n",
    "    is_training = tf.placeholder(tf.bool)\n",
    "\n",
    "    logits = vgg16(images, is_training)\n",
    "    loss, iou_metric, predict_object, predict_class, predict_normalized_box = loss_layer(logits, labels)\n",
    "            \n",
    "    optimizer = tf.train.AdamOptimizer(lr)\n",
    "    train_op = optimizer.minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0 - running_time: 94s - train_loss: 1.347 - train_iou: 0.392 - val_loss: 1.289 - val_iou: 0.509\n",
      "epoch: 1 - running_time: 88s - train_loss: 0.323 - train_iou: 0.610 - val_loss: 0.319 - val_iou: 0.595\n",
      "epoch: 2 - running_time: 87s - train_loss: 0.188 - train_iou: 0.653 - val_loss: 0.210 - val_iou: 0.669\n",
      "epoch: 3 - running_time: 89s - train_loss: 0.160 - train_iou: 0.653 - val_loss: 0.186 - val_iou: 0.642\n",
      "epoch: 4 - running_time: 89s - train_loss: 0.130 - train_iou: 0.723 - val_loss: 0.164 - val_iou: 0.663\n",
      "epoch: 5 - running_time: 89s - train_loss: 0.127 - train_iou: 0.796 - val_loss: 0.143 - val_iou: 0.701\n",
      "epoch: 6 - running_time: 89s - train_loss: 0.124 - train_iou: 0.785 - val_loss: 0.128 - val_iou: 0.754\n",
      "epoch: 7 - running_time: 89s - train_loss: 0.084 - train_iou: 0.804 - val_loss: 0.107 - val_iou: 0.790\n",
      "epoch: 8 - running_time: 89s - train_loss: 0.110 - train_iou: 0.773 - val_loss: 0.127 - val_iou: 0.769\n",
      "epoch: 9 - running_time: 89s - train_loss: 0.076 - train_iou: 0.825 - val_loss: 0.097 - val_iou: 0.812\n",
      "epoch: 10 - running_time: 88s - train_loss: 0.065 - train_iou: 0.819 - val_loss: 0.091 - val_iou: 0.815\n",
      "epoch: 11 - running_time: 89s - train_loss: 0.061 - train_iou: 0.831 - val_loss: 0.090 - val_iou: 0.833\n",
      "epoch: 12 - running_time: 89s - train_loss: 0.054 - train_iou: 0.854 - val_loss: 0.086 - val_iou: 0.839\n",
      "epoch: 13 - running_time: 90s - train_loss: 0.052 - train_iou: 0.847 - val_loss: 0.089 - val_iou: 0.844\n",
      "epoch: 14 - running_time: 90s - train_loss: 0.080 - train_iou: 0.781 - val_loss: 0.105 - val_iou: 0.804\n",
      "epoch: 15 - running_time: 89s - train_loss: 0.048 - train_iou: 0.846 - val_loss: 0.084 - val_iou: 0.845\n",
      "epoch: 16 - running_time: 88s - train_loss: 0.046 - train_iou: 0.850 - val_loss: 0.082 - val_iou: 0.830\n",
      "epoch: 17 - running_time: 88s - train_loss: 0.055 - train_iou: 0.843 - val_loss: 0.093 - val_iou: 0.800\n",
      "epoch: 18 - running_time: 89s - train_loss: 0.040 - train_iou: 0.862 - val_loss: 0.081 - val_iou: 0.845\n",
      "epoch: 19 - running_time: 89s - train_loss: 0.042 - train_iou: 0.853 - val_loss: 0.098 - val_iou: 0.811\n",
      "epoch: 20 - running_time: 89s - train_loss: 0.039 - train_iou: 0.860 - val_loss: 0.081 - val_iou: 0.848\n",
      "epoch: 21 - running_time: 89s - train_loss: 0.035 - train_iou: 0.875 - val_loss: 0.079 - val_iou: 0.859\n",
      "epoch: 22 - running_time: 89s - train_loss: 0.033 - train_iou: 0.879 - val_loss: 0.079 - val_iou: 0.853\n",
      "epoch: 23 - running_time: 89s - train_loss: 0.035 - train_iou: 0.873 - val_loss: 0.081 - val_iou: 0.863\n",
      "epoch: 24 - running_time: 89s - train_loss: 0.035 - train_iou: 0.870 - val_loss: 0.080 - val_iou: 0.849\n",
      "epoch: 25 - running_time: 87s - train_loss: 0.033 - train_iou: 0.882 - val_loss: 0.074 - val_iou: 0.869\n",
      "epoch: 26 - running_time: 89s - train_loss: 0.040 - train_iou: 0.859 - val_loss: 0.079 - val_iou: 0.855\n",
      "epoch: 27 - running_time: 89s - train_loss: 0.034 - train_iou: 0.883 - val_loss: 0.081 - val_iou: 0.860\n",
      "epoch: 28 - running_time: 89s - train_loss: 0.031 - train_iou: 0.879 - val_loss: 0.081 - val_iou: 0.852\n",
      "epoch: 29 - running_time: 89s - train_loss: 0.032 - train_iou: 0.876 - val_loss: 0.081 - val_iou: 0.864\n",
      "epoch: 30 - running_time: 89s - train_loss: 0.030 - train_iou: 0.886 - val_loss: 0.077 - val_iou: 0.863\n",
      "epoch: 31 - running_time: 89s - train_loss: 0.031 - train_iou: 0.886 - val_loss: 0.076 - val_iou: 0.870\n",
      "epoch: 32 - running_time: 89s - train_loss: 0.033 - train_iou: 0.876 - val_loss: 0.080 - val_iou: 0.854\n",
      "epoch: 33 - running_time: 89s - train_loss: 0.041 - train_iou: 0.860 - val_loss: 0.087 - val_iou: 0.836\n",
      "epoch: 34 - running_time: 89s - train_loss: 0.030 - train_iou: 0.887 - val_loss: 0.078 - val_iou: 0.870\n",
      "epoch: 35 - running_time: 89s - train_loss: 0.030 - train_iou: 0.884 - val_loss: 0.080 - val_iou: 0.869\n",
      "epoch: 36 - running_time: 89s - train_loss: 0.031 - train_iou: 0.876 - val_loss: 0.079 - val_iou: 0.879\n",
      "epoch: 37 - running_time: 89s - train_loss: 0.028 - train_iou: 0.890 - val_loss: 0.078 - val_iou: 0.872\n",
      "epoch: 38 - running_time: 89s - train_loss: 0.127 - train_iou: 0.778 - val_loss: 0.114 - val_iou: 0.759\n",
      "epoch: 39 - running_time: 89s - train_loss: 0.068 - train_iou: 0.838 - val_loss: 0.091 - val_iou: 0.820\n",
      "epoch: 40 - running_time: 89s - train_loss: 0.047 - train_iou: 0.849 - val_loss: 0.090 - val_iou: 0.831\n",
      "epoch: 41 - running_time: 89s - train_loss: 0.036 - train_iou: 0.863 - val_loss: 0.080 - val_iou: 0.851\n",
      "epoch: 42 - running_time: 89s - train_loss: 0.032 - train_iou: 0.877 - val_loss: 0.074 - val_iou: 0.868\n",
      "epoch: 43 - running_time: 89s - train_loss: 0.028 - train_iou: 0.882 - val_loss: 0.072 - val_iou: 0.871\n",
      "epoch: 44 - running_time: 88s - train_loss: 0.027 - train_iou: 0.887 - val_loss: 0.072 - val_iou: 0.875\n",
      "epoch: 45 - running_time: 88s - train_loss: 0.031 - train_iou: 0.879 - val_loss: 0.075 - val_iou: 0.875\n",
      "epoch: 46 - running_time: 88s - train_loss: 0.027 - train_iou: 0.895 - val_loss: 0.074 - val_iou: 0.876\n",
      "epoch: 47 - running_time: 88s - train_loss: 0.076 - train_iou: 0.731 - val_loss: 0.180 - val_iou: 0.836\n",
      "epoch: 48 - running_time: 88s - train_loss: 0.032 - train_iou: 0.868 - val_loss: 0.084 - val_iou: 0.857\n",
      "epoch: 49 - running_time: 88s - train_loss: 0.027 - train_iou: 0.888 - val_loss: 0.071 - val_iou: 0.874\n",
      "epoch: 50 - running_time: 88s - train_loss: 0.025 - train_iou: 0.898 - val_loss: 0.070 - val_iou: 0.882\n",
      "epoch: 51 - running_time: 87s - train_loss: 0.028 - train_iou: 0.889 - val_loss: 0.075 - val_iou: 0.874\n",
      "epoch: 52 - running_time: 87s - train_loss: 0.024 - train_iou: 0.898 - val_loss: 0.071 - val_iou: 0.882\n",
      "epoch: 53 - running_time: 88s - train_loss: 0.027 - train_iou: 0.888 - val_loss: 0.077 - val_iou: 0.864\n",
      "epoch: 54 - running_time: 88s - train_loss: 0.025 - train_iou: 0.889 - val_loss: 0.077 - val_iou: 0.874\n",
      "epoch: 55 - running_time: 88s - train_loss: 0.025 - train_iou: 0.891 - val_loss: 0.075 - val_iou: 0.874\n",
      "epoch: 56 - running_time: 88s - train_loss: 0.025 - train_iou: 0.908 - val_loss: 0.072 - val_iou: 0.877\n",
      "epoch: 57 - running_time: 87s - train_loss: 0.023 - train_iou: 0.907 - val_loss: 0.071 - val_iou: 0.884\n",
      "epoch: 58 - running_time: 87s - train_loss: 0.027 - train_iou: 0.880 - val_loss: 0.081 - val_iou: 0.858\n",
      "epoch: 59 - running_time: 87s - train_loss: 0.022 - train_iou: 0.903 - val_loss: 0.072 - val_iou: 0.869\n",
      "epoch: 60 - running_time: 87s - train_loss: 0.020 - train_iou: 0.906 - val_loss: 0.074 - val_iou: 0.886\n",
      "epoch: 61 - running_time: 87s - train_loss: 0.023 - train_iou: 0.902 - val_loss: 0.068 - val_iou: 0.884\n",
      "epoch: 62 - running_time: 87s - train_loss: 0.020 - train_iou: 0.904 - val_loss: 0.074 - val_iou: 0.876\n",
      "epoch: 63 - running_time: 88s - train_loss: 0.021 - train_iou: 0.910 - val_loss: 0.071 - val_iou: 0.885\n",
      "epoch: 64 - running_time: 87s - train_loss: 0.026 - train_iou: 0.905 - val_loss: 0.073 - val_iou: 0.891\n",
      "epoch: 65 - running_time: 87s - train_loss: 0.020 - train_iou: 0.917 - val_loss: 0.073 - val_iou: 0.890\n",
      "epoch: 66 - running_time: 88s - train_loss: 0.020 - train_iou: 0.909 - val_loss: 0.075 - val_iou: 0.887\n",
      "epoch: 67 - running_time: 87s - train_loss: 0.019 - train_iou: 0.903 - val_loss: 0.075 - val_iou: 0.886\n",
      "epoch: 68 - running_time: 87s - train_loss: 0.030 - train_iou: 0.873 - val_loss: 0.087 - val_iou: 0.853\n",
      "epoch: 69 - running_time: 87s - train_loss: 0.029 - train_iou: 0.882 - val_loss: 0.083 - val_iou: 0.864\n",
      "epoch: 70 - running_time: 87s - train_loss: 0.025 - train_iou: 0.878 - val_loss: 0.081 - val_iou: 0.868\n",
      "epoch: 71 - running_time: 87s - train_loss: 0.020 - train_iou: 0.907 - val_loss: 0.072 - val_iou: 0.884\n",
      "epoch: 72 - running_time: 87s - train_loss: 0.025 - train_iou: 0.895 - val_loss: 0.076 - val_iou: 0.868\n",
      "epoch: 73 - running_time: 87s - train_loss: 0.049 - train_iou: 0.771 - val_loss: 0.095 - val_iou: 0.804\n",
      "epoch: 74 - running_time: 87s - train_loss: 0.021 - train_iou: 0.895 - val_loss: 0.073 - val_iou: 0.876\n",
      "epoch: 75 - running_time: 87s - train_loss: 0.020 - train_iou: 0.910 - val_loss: 0.071 - val_iou: 0.888\n",
      "epoch: 76 - running_time: 87s - train_loss: 0.020 - train_iou: 0.910 - val_loss: 0.073 - val_iou: 0.887\n",
      "epoch: 77 - running_time: 87s - train_loss: 0.020 - train_iou: 0.915 - val_loss: 0.072 - val_iou: 0.897\n",
      "epoch: 78 - running_time: 87s - train_loss: 0.020 - train_iou: 0.912 - val_loss: 0.075 - val_iou: 0.884\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 79 - running_time: 87s - train_loss: 0.018 - train_iou: 0.916 - val_loss: 0.074 - val_iou: 0.893\n",
      "epoch: 80 - running_time: 87s - train_loss: 0.017 - train_iou: 0.911 - val_loss: 0.077 - val_iou: 0.888\n",
      "epoch: 81 - running_time: 87s - train_loss: 0.019 - train_iou: 0.912 - val_loss: 0.075 - val_iou: 0.889\n",
      "epoch: 82 - running_time: 87s - train_loss: 0.045 - train_iou: 0.814 - val_loss: 0.097 - val_iou: 0.810\n",
      "epoch: 83 - running_time: 88s - train_loss: 0.019 - train_iou: 0.903 - val_loss: 0.075 - val_iou: 0.878\n",
      "epoch: 84 - running_time: 87s - train_loss: 0.017 - train_iou: 0.914 - val_loss: 0.078 - val_iou: 0.886\n",
      "epoch: 85 - running_time: 87s - train_loss: 0.034 - train_iou: 0.867 - val_loss: 0.079 - val_iou: 0.854\n",
      "epoch: 86 - running_time: 87s - train_loss: 0.021 - train_iou: 0.899 - val_loss: 0.081 - val_iou: 0.875\n",
      "epoch: 87 - running_time: 87s - train_loss: 0.018 - train_iou: 0.907 - val_loss: 0.073 - val_iou: 0.879\n",
      "epoch: 88 - running_time: 87s - train_loss: 0.015 - train_iou: 0.911 - val_loss: 0.073 - val_iou: 0.894\n",
      "epoch: 89 - running_time: 87s - train_loss: 0.014 - train_iou: 0.915 - val_loss: 0.077 - val_iou: 0.874\n",
      "epoch: 90 - running_time: 87s - train_loss: 0.015 - train_iou: 0.916 - val_loss: 0.078 - val_iou: 0.890\n",
      "epoch: 91 - running_time: 87s - train_loss: 0.015 - train_iou: 0.920 - val_loss: 0.075 - val_iou: 0.900\n",
      "epoch: 92 - running_time: 87s - train_loss: 0.012 - train_iou: 0.924 - val_loss: 0.075 - val_iou: 0.896\n",
      "epoch: 93 - running_time: 87s - train_loss: 0.014 - train_iou: 0.924 - val_loss: 0.075 - val_iou: 0.897\n",
      "epoch: 94 - running_time: 87s - train_loss: 0.017 - train_iou: 0.904 - val_loss: 0.077 - val_iou: 0.895\n",
      "epoch: 95 - running_time: 87s - train_loss: 0.017 - train_iou: 0.922 - val_loss: 0.072 - val_iou: 0.899\n",
      "epoch: 96 - running_time: 87s - train_loss: 0.016 - train_iou: 0.927 - val_loss: 0.071 - val_iou: 0.901\n",
      "epoch: 97 - running_time: 87s - train_loss: 0.013 - train_iou: 0.923 - val_loss: 0.073 - val_iou: 0.895\n",
      "epoch: 98 - running_time: 87s - train_loss: 0.014 - train_iou: 0.916 - val_loss: 0.076 - val_iou: 0.895\n",
      "epoch: 99 - running_time: 87s - train_loss: 0.013 - train_iou: 0.919 - val_loss: 0.075 - val_iou: 0.896\n"
     ]
    }
   ],
   "source": [
    "with tf.Session(graph=graph) as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    saver = tf.train.Saver(max_to_keep=1)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        start_time = time.time()\n",
    "        for batch in range(len(X_train)//batch_size):\n",
    "            X_batch = X_train[batch*batch_size:(batch+1)*batch_size]\n",
    "            y_batch = y_train[batch*batch_size:(batch+1)*batch_size]\n",
    "            train_total_loss, train_iou_m,_ = sess.run([loss, iou_metric, train_op], {images:X_batch, labels:y_batch, is_training:True})            \n",
    "        end_time = time.time()\n",
    "        \n",
    "        val_loss = []\n",
    "        val_iou_ms = []\n",
    "        for batch in range(len(X_test)//batch_size):\n",
    "            val_X_batch = X_test[batch*batch_size:(batch+1)*batch_size]\n",
    "            val_y_batch = y_test[batch*batch_size:(batch+1)*batch_size]\n",
    "            total_val_loss, val_iou_m, val_predict_object, val_predict_class, val_predict_normalized_box = sess.run([loss, iou_metric, predict_object, predict_class, predict_normalized_box], \n",
    "                                                 {images:val_X_batch, labels:val_y_batch, is_training:False})\n",
    "            val_loss.append(total_val_loss)\n",
    "            val_iou_ms.append(val_iou_m)\n",
    "            \n",
    "        saver.save(sess, './model/yolo', global_step=epoch)\n",
    "        print('epoch: {} - running_time: {:.0f}s - train_loss: {:.3f} - train_iou: {:.3f} - val_loss: {:.3f} - val_iou: {:.3f}'.format(epoch, end_time - start_time, train_total_loss, train_iou_m, np.mean(val_loss), np.mean(val_iou_ms)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def iou(box1, box2):\n",
    "        tb = min(box1[0] + 0.5 * box1[2], box2[0] + 0.5 * box2[2]) - \\\n",
    "            max(box1[0] - 0.5 * box1[2], box2[0] - 0.5 * box2[2])\n",
    "        lr = min(box1[1] + 0.5 * box1[3], box2[1] + 0.5 * box2[3]) - \\\n",
    "            max(box1[1] - 0.5 * box1[3], box2[1] - 0.5 * box2[3])\n",
    "        inter = 0 if tb < 0 or lr < 0 else tb * lr\n",
    "        return inter / (box1[2] * box1[3] + box2[2] * box2[3] - inter)\n",
    "    \n",
    "def interpret_output(predict_object, predict_class, predict_normalized_box):\n",
    "    predict_box= predict_normalized_box*img_size\n",
    "    predict_object = np.expand_dims(predict_object, axis=-1)\n",
    "    predict_class = np.expand_dims(predict_class, axis=-2)\n",
    "    class_probs = predict_object*predict_class\n",
    "    \n",
    "    filter_mat_probs = np.array(class_probs >= 0.2, dtype='bool')\n",
    "    filter_mat_boxes = np.nonzero(filter_mat_probs)\n",
    "    boxes_filtered = predict_box[filter_mat_boxes[0], filter_mat_boxes[1], filter_mat_boxes[2]]\n",
    "    class_probs_filtered = class_probs[filter_mat_probs]\n",
    "       \n",
    "    classes_num_filtered = np.argmax(\n",
    "        filter_mat_probs, axis=3)[\n",
    "        filter_mat_boxes[0], filter_mat_boxes[1], filter_mat_boxes[2]]\n",
    "\n",
    "    argsort = np.array(np.argsort(class_probs_filtered))[::-1]\n",
    "    boxes_filtered = boxes_filtered[argsort]\n",
    "    class_probs_filtered = class_probs_filtered[argsort]\n",
    "    classes_num_filtered = classes_num_filtered[argsort]\n",
    "\n",
    "    for i in range(len(boxes_filtered)):\n",
    "        if class_probs_filtered[i] == 0:\n",
    "            continue\n",
    "        for j in range(i + 1, len(boxes_filtered)):\n",
    "            if iou(boxes_filtered[i], boxes_filtered[j]) > 0.5:\n",
    "                class_probs_filtered[j] = 0.0\n",
    "\n",
    "    filter_iou = np.array(class_probs_filtered > 0.0, dtype='bool')\n",
    "    boxes_filtered = boxes_filtered[filter_iou]\n",
    "    class_probs_filtered = class_probs_filtered[filter_iou]\n",
    "    classes_num_filtered = classes_num_filtered[filter_iou]\n",
    "\n",
    "    result = []\n",
    "    for i in range(len(boxes_filtered)):\n",
    "        result.append(\n",
    "            [classes_num_filtered[i],\n",
    "             boxes_filtered[i][0],\n",
    "             boxes_filtered[i][1],\n",
    "             boxes_filtered[i][2],\n",
    "             boxes_filtered[i][3],\n",
    "             class_probs_filtered[i]])\n",
    "\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_idx = 8\n",
    "result = interpret_output(val_predict_object[img_idx], val_predict_class[img_idx], val_predict_normalized_box[img_idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 400x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def draw_result(img, result):\n",
    "    plt.figure(figsize=(10,10), dpi=40)\n",
    "    img = np.pad(img, [(50,50), (50,50), (0,0)], mode='constant', constant_values=255)\n",
    "    for i in range(len(result)):\n",
    "        x = int(result[i][1])+50\n",
    "        y = int(result[i][2])+50\n",
    "        w = int(result[i][3] / 2)\n",
    "        h = int(result[i][4] / 2)\n",
    "        cv2.rectangle(img, (x - w, y - h), (x + w, y + h), (231, 76, 60), 2)\n",
    "        cv2.rectangle(img, (x - w, y - h - 20),\n",
    "                      (x -w + 50, y - h), (46, 204, 113), -1)\n",
    "        cv2.putText(\n",
    "            img, '{} : {:.2f}'.format(result[i][0] ,result[i][5]),\n",
    "            (x - w + 5, y - h - 7), cv2.FONT_HERSHEY_SIMPLEX, 0.3,\n",
    "            (0, 0, 0), 1, cv2.LINE_AA)\n",
    "\n",
    "    #\n",
    "    plt.imshow(img)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "            \n",
    "draw_result(val_X_batch[img_idx]*255, result)            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x = np.nonzero(val_y_batch[img_idx][:,:,0])\n",
    "# x_label =  np.concatenate([val_y_batch[img_idx][x[0], x[1]][:,:5],\n",
    "#         np.argmax(val_y_batch[img_idx][x[0], x[1]][:,5:], axis=1).reshape((5,1))],\n",
    "#                   axis=-1)\n",
    "# draw_result(val_X_batch[img_idx]*255, x_label)            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
